#+TITLE: Building the containers with docker
#+DESCRIPTION: Usa docker para construir contenedores de imágenes para empacar
una aplicación y sus dependencias y así hacer un despliegue en una sola máquina
#+AUTHOR: Sergio Benítez
#+DATE:<2020-11-10 Tue> 

* Por qué Docker

Luego de tener un conocimiento sólido sobre el diseño de aplicaciones modernas
a través del patrón de diseño de microservicios, el siguiente paso es desplegar
el código.

El primer criterio a considerar es las dependecias de las aplicaciones. La
secuencia empezaría con la construcción de paquetes y distribuir todas estas
aplicaciones, y es de esperarse que eso requiera mucho trabajo.

Una opción es decifrar todas las dependecias y construir un paquete nativo para
cada distribución de linux que se quierar soportar, ó se puede omitir este
enfoque y contruir un contenedor de imagen.

Ahora bien, ¿qué es un contenedor de imagen?. Básicamente, es un formato de
empaque que no solo incluye la aplicación, sino todas las dependencias o
información de tiempo de ejecución requerida para ejecutarla.

Una analogía adecuada, es un teléfono celular. En su celular, se descarga una
aplicación autocontenida y la ejecuta. Los contenedores son la misma cosa,
pero para sus servidores. La tecnología de contenedores esta construida para la
mayoría de los sistemas operativos, pero no es precisamente fácil de usar desde
el primer momento. Para ello, es necesario una herramienta como docker, ya que
provee un API con las último en la tecnología de contenedores y facilita la 
/creación/, /distribución/ y la /ejecución/ de contenedores de imágenes en los
servidores.

** Tutorial básico de docker
1. Clonar: se pueden clonar imágenes en repositorios de GitHub, los cuales
contienen todo lo necesario para construir la imagen y correrla como un
contenedor. Los siguientes comandos permiten clonar un respositorio de  prueba
suministrado por docker:

#+begin_src bash
docker run --name repo alpine/git clone \ 
https://github.com/docker/gettign-started.git

docker cp repo:/git/getting-started/ .
#+end_src

2. Build: Ahora, es tiempo de construir la imagen. Una imagen de docker es un
sistema privado de archivos para tu contenedor. El provee todos los archivos y
el código que el contenedor precisa.

#+begin_src bash
cd getting-started

docker build -t docker101tutorial .
#+end_src

3. Run: Ejecute su primer contenedor. Inicie el contenedor basado en la imagen
que se construyó en el paso previo. Al ejecutar el contenedor se lanza la
aplicación con recursos privados, asegurados y aislados del resto de tu máquina.

#+begin_src bash
docker run -d -p 80:80 --name docker-tutorial docker101tutorial
#+end_src

4. Share: Por último, salve y comparta su imagen en Docker Hub con el fin de que
otros usuarios puedan descargarla y ejecutarla en cualquier máquina.

#+begin_src bash
docker tag docker101tutorial username/docker101tutorial

docker push username/docker101tutorial
#+end_src

* Revisión general de docker

Docker és una herramienta open source que hace fácil la creación, distribución y
y ejecución de aplicaciones. Lo hace empaquetando las aplicaciones como un
conjunto de contenedores de imágenes que envuelve todas las dependencias
incluidas con él.

Los contenedores de imágenes pueden correr en cualquier máquina que tenga docker
instalado, haciendo posible el sueño de cualquier administrador de paquetes, ya
que docker ofrece contendores reproducibles y consistentes.

Al igual que los procesos en un computadores, los contenedores pueden prenderse
y apagarse rápidamente. Al mismo tiempo, los contenedores proveen los beneficios
de una máquina virual como el aislamiento entre las aplicaciones que se están
ejecutando en una misma máquina. Por ende, no hay preocupaciones por conflictos
de dependencias entre aplicaciones.

* Instalando aplicaciones con herramientas nativas del sistema operativo

Luego de conectase  al GCS, se va a dar un vistazo a como administrar
aplicaciones sin docker. Para empezar se crea una máquina virtual de Ubuntu para
jugar con ella usando el gcloud.

#+begin_src bash
$ gcloud config set project [PROJECT_ID]
$ gcloud compute instances create ubuntu --image-project ubuntu-os-cloud --image ubuntu-1604-xenial-v20160429
#+end_src

Al crear la máquina virtual, se usa el commando ssh de gcloud para establecer la
conxexión con dicha máquina:

#+begin_src bash
$ gcloud compute ssh ubuntu
#+end_src

Para validar la conexión a la máquina virtual, en el shell debe aparecer la 
siguiente información al inicio de cada línea: ~username@ubuntu:~$~.

Ahora, con ayuda de un administrador de paquetes nativos se va a instalar NGINX
y todas sus dependencias:

#+begin_src bash
$ sudo apt-get update
$ sudo apt-get install nginx
#+end_src

La instalación de NGINX se valida con el comando ~nginx -v~ y la consola
imprimirá una salida como esta: ~nginx version: nginx/1.10.3 (Ubuntu)~.
Complementariamente, para saber si NGINX está corriendo, se usa el comando 
~systemctl~.

#+begin_src bash
$ sudo systemctl status nginx
#+end_src

Este comando imprime los logs relacionados al estado de NGINX, y así se podrá
saber si esta siendo ejecutado. Por último, se prueba si NIGNX esta disponible
localmente con ayuda del ~curl~:

#+begin_src bash
$ curl http://127.0.0.0
#+end_src

¡Perfecto! los sistemas operativos modernos hacen muy fácil instalar, iniciar y
ejecutar aplicaciones.

* Problema: ¿Cómo instalar dos versiones?
Ahora se tratará de instalar dos versiones de NGINX en la máquina virtual. Si se
instala nuevamente usando el administrador de paquetes nativo se obtiene un
mensaje diciendo que NGINX ya está instalado con su última versión.

Al usar el comando ~systemctl~ se observa que solo esta corriendo una instancia
de NGINX y para confirmar dicho ustado se usa el comando ~ps~ en conjunto con
~grep~ como se muestra a continuación:

#+begin_src bash
$ sudo ps aux | grep nginx
#+end_src

En está salida se indica que solo hay un proceso NGINX corriendo con su
respectivo worker. Por lo tanto, solo hay una instancia principal de la
aplicación que se esta ejecutando.

Para lograr crear dos instancias de NGINX en la misma máquina virual usando las
herramientas nativas del sistema operativo es necesario modificar los scripts de
inicialización. Para el caso puntual de NGINX, los cambios irián en el archivo
~/etc/init/nginx.conf~.

Adicionalmente, se requiere administrar los puertos, ya que las dos instancias
no pueden enlazarse al mismo puerto. En resumen, hay mucha complejidad para
hacer las configuraciones con las herramientas nativas del sistema operativo y 
lograr correr dos instancias de NGINX con versiones diferentes en la misma
máquina virtual.

Por defecto, la mayoría de los sistemas operativos solo permite instalar una
versión de una aplicación y ejecutar una instancia de la misma. Eso significa
que para lograr el propósito de correr dos instancias de una misma aplicación
con versiones diferentes en una máquina virtual hay que reconsiderar el enfoque.
Este nuevo enfoque son los contenedores.

* Revisión general del contendor

Los contenedores fueron desarrollados para solucionar los problemas con la
instalación y ejecución de software a través de diferentes sistemas operativos.

Ya se ha visto los problemas de instalar y ejecutar aplicaciones sobre una única
máquina. Ahora, imaginesé instalar NGINX en multiples máquinas y a través de
diferentes sistemas operativos. Eso sería una pesadilla.

Con contenedores se obtienen paquetes autocontenidos /independientes/ que evitan
conflictos con las versiones. Eso es parte del atractivo de los contenedores de
imágenes. Ellos son fáciles de distribuir porque se encargan de todas sus
dependencias por si mismos.

Adicionalmente, los contendores ofrecen /aislamiento/ sobre varios procesos.
En secciones previas, se habló de aislamiento a nivel de sistema de archivos,
pero también existen otros tipos de aislamiento, como por ejemplo el aislamiento
 de red. El aislamiento de red significa que cada instancia tendrá su propia 
dirección IP, y por ende cada máquina tendrá disponible el puerto 80, que es el
puerto por defecto utilizado por NGINX, ahorrando así los problemas de lidiar
con la configuración de los scripts de inicialización. 

Algo importante para considerar, es que mientras se corran dos máquinas 
virtuales en un computador, se tendrán dos sistemas operativos completamente
separados, y multiples contenedores se ejecutaran sobre el mismo sistema 
operativo, debido a que los contenedores son una construcción lógica usada
dentro del sistema operativo. Esto hace que los contenedores sean ligeros y sean
fáciles de prender o apagar.

* Instalando imágenes con docker
  
#+begin_src bash
sudo apt-get install docker.io
#+end_src

#+begin_src bash
sudo docker images
#+end_src

#+begin_src bash
sudo docker pull nginx:1.10.0
#+end_src

#+begin_src bash
sudo dpkg -l | grep nginx
#+end_src
