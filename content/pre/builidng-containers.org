#+TITLE: Building the containers with docker
#+DESCRIPTION: Usa docker para construir contenedores de imágenes para empacar
una aplicación y sus dependencias y así hacer un despliegue en una sola máquina
#+AUTHOR: Sergio Benítez
#+DATE:<2020-11-10 Tue> 

* Por qué Docker

Luego de tener un conocimiento sólido sobre el diseño de aplicaciones modernas
a través del patrón de diseño de microservicios, el siguiente paso es desplegar
el código.

El primer criterio a considerar es las dependecias de las aplicaciones. La
secuencia empezaría con la construcción de paquetes y distribuir todas estas
aplicaciones, y es de esperarse que eso requiera mucho trabajo.

Una opción es decifrar todas las dependecias y construir un paquete nativo para
cada distribución de linux que se quierar soportar, ó se puede omitir este
enfoque y contruir on contenedor de imagen.

Ahora bien, ¿qué es un contenedor de imagen?. Básicamente, es un formato de
empaque que no solo incluye la aplicación, sino toda las dependencias o
información de tiempo de ejecución requerida para ejecutarla.

Una analogía adecuada, es un teléfono celular. Usted descarga una aplicación
autocontenida y la ejecuta. Los contenedores son la misma cosa, pero para sus
servidores. La tecnología de contenedores esta construida para la mayoría de los
sistemas operativos, pero no es precisamente fácil de usar desde el primer
momento. Para ello, es necesario una herramienta como docker, ya que provee un
API con las último en la tecnología de contenedores y facilita la /creación/,
/distribución/ y la /ejecución/ de contenedores de imagenes en los servidores.

** Tutorial básico de docker
1. Clonar: podemos clonar imágenes en repositorios de GitHub, los cuales
contienen todo lo necesario para construir la imagen y correrla como un
contenedor. Los siguientes comandos nos permiten clonar un respositorio de 
prueba suministrado por docker:

#+begin_src bash
docker run --name repo alpine/git clone \ 
https://github.com/docker/gettign-started.git

docker cp repo:/git/getting-started/ .
#+end_src

2. Build: Ahora, es tiempo de construir la imagen. Una imagen de docker es un
sistema privado de archivos para tu contenedor. El provee todos los archivos y
el código que el contenedor precisa.

#+begin_src bash
cd getting-started

docker build -t docker101tutorial .
#+end_src

3. Run: Ejecuta tu primer contenedor. Inicie el contenedor basado en la imagen
que se construyó en el paso previo. Ejecutar el contenedor lanza la aplicación
con recursos privados, asegurados y aislados del resto de tu máquina.

#+begin_src bash
docker run -d -p 80:80 --name docker-tutorial docker101tutorial
#+end_src

4. Share: Por último, salva y comparte tu imagen en Docker Hub con el fin de que
otros usuarios puedan descargarla y ejecutarla en cualquier máquina.

#+begin_src bash
docker tag docker101tutorial username/docker101tutorial

docker push username/docker101tutorial
#+end_src

* Revisión general de docker

Docker és una herramienta open source que hace fácil la creación, distribución y
y ejecución de aplicaciones. Lo hace empaquetando las aplicaciones como un
conjunto de contenedores de imágenes que envuelve todas las dependencias
incluidas con él.

Los contenedores de imágenes pueden correr en cualquier máquina que tenga docker
instalado, haciendo posible el sueño de cualquier administrador de paquetes, ya
que docker ofrece contendores reproducible y consistentes.

Al igual que los procesos en un computadores, los contenedores pueden prenderse
y apagarse rápidamente. Al mismo tiempo, los contenedores proveen los beneficios
de una máquina virual como el aislamiento entre las aplicaciones que se están
ejecutando en una misma máquina. Por ende, no tenemos que preocuparnos por
conflictos de dependencias entre aplicaciones.

* Instalando aplicaciones con herramientas nativas del sistema operativo

Una vez conectados al GCS, vamos a dar un vistazo a como administrar
aplicaciones sin docker. Empezemos creando una máquina virtual de Ubuntu para
jugar con ella usando el gcloud.

#+begin_src bash
$ gcloud config set project [PROJECT_ID]
$ gcloud compute instances create ubuntu --image-project ubuntu-os-cloud --image ubuntu-1604-xenial-v20160429
#+end_src

Al crear la máquina virtual, nos podemos conectar a ella usando el commando ssh
de gcloud:


#+begin_src bash
$ gcloud compute ssh ubuntu
#+end_src

Para validar que estamos conectados a la máquina virtual, en el shell de
aparecer la siguiente información al inicio de cada línea: ~username@ubuntu:~$~.

Ahora, con ayuda de un administrador de paquetes nativos se va a instalar NGINX
y todas sus dependencias:

#+begin_src bash
$ sudo apt-get update
$ sudo apt-get install nginx
#+end_src

Validamos la instalación de NGINX con el comando ~nginx -v~ y la consola
imprimirá una salida como esta: ~nginx version: nginx/1.10.3 (Ubuntu)~.
Complementariamente, para saber si NGINX está corriendo, podemos usar el comando 
~systemctl~.

#+begin_src bash
$ sudo systemctl status nginx
#+end_src

Este comando imprime los logs relacionados al estado de NGINX, y así se podrá
saber si esta siendo ejecutado. Por último, se prueba si NIGNX esta disponible
localmente con ayuda del ~curl~:

#+begin_src bash
$ curl http://127.0.0.0
#+end_src

¡Perfecto! los sistemas operativos modernos hacen muy fácil instalar, iniciar y
ejecutar aplicaciones.
